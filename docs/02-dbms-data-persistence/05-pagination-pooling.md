---
title: "4. Pagination & Connection Pooling"
sidebar_position: 5
description: Offset vs Cursor Pagination and HikariCP Configuration.
---

# Pagination & Connection Pooling

:::info Interview Importance â­â­â­â­
Pagination is asked in almost every system design interview. Connection pooling is crucial for production-grade applications.
:::

---

## 1. Pagination Strategies

### Why Pagination Matters

Imagine a table with 10 million records. Returning all of them would:
- ğŸ”¥ Overload the database
- ğŸ¢ Slow down the network
- ğŸ’¥ Crash the client application
- ğŸ“ˆ Consume excessive memory

**Solution:** Return data in pages (chunks).

---

## 2. Offset Pagination (The Traditional Way)

### How It Works

```sql
-- Page 1 (first 10 results)
SELECT * FROM products ORDER BY id LIMIT 10 OFFSET 0;

-- Page 2 (next 10 results)
SELECT * FROM products ORDER BY id LIMIT 10 OFFSET 10;

-- Page 100 (results 991-1000)
SELECT * FROM products ORDER BY id LIMIT 10 OFFSET 990;
```

### The Problem: Performance Degrades with OFFSET

```
LIMIT 10 OFFSET 1,000,000

What the database does:
1. Scan and sort ALL 1,000,000+ rows
2. Skip first 1,000,000 rows (WASTED WORK!)
3. Return only 10 rows

Time complexity: O(N) where N = offset value
```

```
Performance Comparison:

OFFSET 0:      â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  10ms
OFFSET 10000:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  100ms
OFFSET 100000: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  500ms
OFFSET 1000000:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 5000ms+
```

### When to Use Offset Pagination

| Scenario | Offset OK? | Reason |
|----------|------------|--------|
| Small tables (10K rows) | âœ… Yes | Fast enough |
| Admin dashboards | âœ… Yes | Few users, admin can wait |
| Page jump required ("Go to page 50") | âœ… Yes | No other option |
| Mobile app infinite scroll | âŒ No | Too slow for deep pages |
| API with millions of records | âŒ No | O(N) too expensive |

---

## 3. Cursor-Based (Keyset) Pagination

### How It Works

Instead of "skip N rows", say "give me rows AFTER this value".

```sql
-- First page
SELECT * FROM products 
WHERE id > 0
ORDER BY id ASC 
LIMIT 10;
-- Returns: id = 1, 2, 3, ..., 10

-- Next page (cursor = last id from previous page = 10)
SELECT * FROM products 
WHERE id > 10  -- Cursor value!
ORDER BY id ASC 
LIMIT 10;
-- Returns: id = 11, 12, 13, ..., 20

-- Next page (cursor = 20)
SELECT * FROM products 
WHERE id > 20
ORDER BY id ASC 
LIMIT 10;
```

### Why It's Faster

```
OFFSET 1,000,000:
â”œâ”€â”€ Scan 1,000,000 rows
â”œâ”€â”€ Discard 1,000,000 rows
â””â”€â”€ Return 10 rows
Time: O(N) â‰ˆ 5 seconds

CURSOR (id > 1000000):
â”œâ”€â”€ Jump directly to id = 1,000,001 (using index!)
â””â”€â”€ Return 10 rows
Time: O(log N) â‰ˆ 5 milliseconds
```

### Implementation Example

**API Response with Cursor:**

```json
{
  "data": [
    {"id": 101, "name": "Product A"},
    {"id": 102, "name": "Product B"},
    {"id": 110, "name": "Product C"}
  ],
  "pagination": {
    "next_cursor": "110",
    "has_more": true
  }
}

// Client requests next page:
// GET /api/products?cursor=110&limit=10
```

**Backend Implementation:**

```java
@GetMapping("/products")
public Page<Product> getProducts(
    @RequestParam(required = false) Long cursor,
    @RequestParam(defaultValue = "10") int limit
) {
    List<Product> products;
    
    if (cursor == null) {
        // First page
        products = productRepo.findTopNByOrderByIdAsc(limit + 1);
    } else {
        // Subsequent pages
        products = productRepo.findByIdGreaterThanOrderByIdAsc(cursor, limit + 1);
    }
    
    boolean hasMore = products.size() > limit;
    if (hasMore) {
        products = products.subList(0, limit);  // Remove extra item
    }
    
    Long nextCursor = hasMore ? products.get(products.size() - 1).getId() : null;
    
    return new Page<>(products, nextCursor, hasMore);
}
```

### Cursor with Multiple Columns

When sorting by non-unique column, include a tiebreaker:

```sql
-- Sort by created_at (non-unique) + id (unique tiebreaker)
SELECT * FROM products 
WHERE (created_at, id) > ('2024-01-15 10:30:00', 12345)
ORDER BY created_at ASC, id ASC
LIMIT 10;
```

**Encoded cursor:**

```java
// Cursor contains both values
String cursor = Base64.encode(createdAt + "|" + id);
// Result: "MjAyNC0wMS0xNSAxMDozMDowMHwxMjM0NQ=="
```

### Comparison: Offset vs Cursor

| Feature | Offset | Cursor |
|---------|--------|--------|
| **Performance** | O(N) - degrades | O(log N) - constant |
| **Jump to page** | âœ… Easy | âŒ Not possible |
| **Consistency** | âŒ Rows can shift | âœ… Stable |
| **Implementation** | Simple | More complex |
| **Use case** | Admin panels | Infinite scroll, APIs |

### Consistency Problem with Offset

```
Time â†’

Initial data: [A, B, C, D, E, F, G, H, I, J]
Page 1 (OFFSET 0, LIMIT 5): [A, B, C, D, E]

Someone inserts 'Z' at position 1

Data now: [Z, A, B, C, D, E, F, G, H, I, J]
Page 2 (OFFSET 5, LIMIT 5): [E, F, G, H, I]

User sees 'E' TWICE! (on both pages)
```

**Cursor doesn't have this problem** because it uses actual values, not positions.

---

## 4. Connection Pooling

### Why Connection Pooling?

Creating a database connection is **expensive**:

```
Connection Creation Steps:
1. TCP 3-way handshake (network round-trip)
2. SSL/TLS negotiation (if encrypted)
3. Database authentication
4. Allocate server-side resources

Time: 50-200ms per connection

If 100 requests/sec each create new connection:
= 100 Ã— 100ms = 10 seconds of just connection overhead!
```

### What is Connection Pooling?

Maintain a pool of **already-open connections** that are reused.

```
Without Pool:                     With Pool:
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
Request 1 â”€â”€â†’ Open â”€â”€â†’ Use â”€â”€â†’ Close   â”‚  Connection Pool    â”‚
Request 2 â”€â”€â†’ Open â”€â”€â†’ Use â”€â”€â†’ Close   â”‚  â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”â”Œâ”€â”€â”€â”    â”‚
Request 3 â”€â”€â†’ Open â”€â”€â†’ Use â”€â”€â†’ Close   â”‚  â”‚C1 â”‚â”‚C2 â”‚â”‚C3 â”‚    â”‚
                                  â”‚  â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜â””â”€â”€â”€â”˜    â”‚
Each request: ~100ms overhead     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â†“    â†“    â†“
                                  Request borrows C1
                                  Request returns C1
                                  Next request reuses C1
                                  
                                  Overhead: ~1ms
```

---

## 5. HikariCP (The Fastest Connection Pool)

### What is HikariCP?

- Default connection pool in **Spring Boot 2.0+**
- Extremely lightweight and fast
- "Hikari" means "light" in Japanese

### Basic Configuration

```yaml
# application.yml
spring:
  datasource:
    hikari:
      # Pool settings
      maximum-pool-size: 10
      minimum-idle: 5
      
      # Timeouts
      connection-timeout: 30000    # 30 seconds to get connection
      idle-timeout: 600000         # 10 minutes before idle connection closed
      max-lifetime: 1800000        # 30 minutes max connection age
      
      # Validation
      connection-test-query: SELECT 1
```

### Key Configuration Options Explained

| Property | Default | Description |
|----------|---------|-------------|
| `maximum-pool-size` | 10 | Max connections in pool |
| `minimum-idle` | Same as max | Min idle connections |
| `connection-timeout` | 30000ms | Time to wait for connection |
| `idle-timeout` | 600000ms | When to close idle connections |
| `max-lifetime` | 1800000ms | Max age of a connection |
| `leak-detection-threshold` | 0 | Detect connection leaks |

---

## 6. Pool Sizing: The Formula

### The Myth: "More Connections = Better"

**Reality:** More connections can actually be SLOWER!

```
Why too many connections hurt:

Database Server (4 CPU cores):
â”œâ”€â”€ 100 connections = 100 threads
â”œâ”€â”€ 4 cores can run 4 threads at once
â”œâ”€â”€ The other 96 threads context-switch constantly
â””â”€â”€ CPU spends more time switching than working!
```

### The Formula (PostgreSQL Wiki)

```
connections = (core_count * 2) + effective_spindle_count

For SSD (spindle_count â‰ˆ 0):
connections â‰ˆ core_count * 2
```

**Example:**
- Server: 4 CPU cores, SSD storage
- Pool size = (4 Ã— 2) + 0 = **8-10 connections**

### General Guidelines

| Server Size | Recommended Pool Size |
|-------------|----------------------|
| Small (2 cores) | 5-10 |
| Medium (4 cores) | 10-20 |
| Large (8 cores) | 20-40 |
| Very Large (16+ cores) | 40-80 |

### Too Small vs Too Large Pool

```
Pool too SMALL (5 connections, 100 concurrent requests):
â”œâ”€â”€ 95 requests wait in queue
â”œâ”€â”€ High latency (waiting for connection)
â””â”€â”€ Underutilized database

Pool too LARGE (500 connections, 100 concurrent requests):
â”œâ”€â”€ Database: 500 connections = 500 threads = context switching hell
â”œâ”€â”€ Memory: 500 connections Ã— 10MB = 5GB just for connections
â””â”€â”€ Actually SLOWER than smaller pool
```

---

## 7. Connection Pool Exhaustion

### The Problem

```
Error: Connection is not available, request timed out after 30000ms

Cause: All connections in pool are "borrowed" and busy
       New requests can't get a connection
```

### Common Causes

#### 1. Connection Leak

```java
// âŒ Connection never returned to pool!
public void badMethod() {
    Connection conn = dataSource.getConnection();
    // Do stuff...
    // MISSING: conn.close();
}

// âœ… Always use try-with-resources
public void goodMethod() {
    try (Connection conn = dataSource.getConnection()) {
        // Do stuff...
    }  // Automatically closed (returned to pool)
}
```

#### 2. Slow Queries

```java
// Connection borrowed for 30 seconds!
@Transactional
public void slowMethod() {
    List<Data> all = repository.findAllHugeTable();  // Takes 30 seconds
    // Connection held during entire processing
}
```

#### 3. Long Transactions

```java
// âŒ HTTP call inside transaction holds connection!
@Transactional
public void badTransaction() {
    order.setStatus("PENDING");
    orderRepo.save(order);
    
    // External API call takes 5 seconds
    paymentService.callExternalApi(order);  // Connection still held!
    
    order.setStatus("PAID");
    orderRepo.save(order);
}

// âœ… HTTP call outside transaction
public void goodTransaction() {
    saveOrderPending();  // Short transaction
    
    PaymentResult result = paymentService.callExternalApi(order);  // No DB connection
    
    if (result.isSuccess()) {
        markOrderPaid();  // Another short transaction
    }
}
```

### How to Detect Connection Leaks

**HikariCP Leak Detection:**

```yaml
spring:
  datasource:
    hikari:
      leak-detection-threshold: 60000  # Log warning if connection held > 60s
```

**Log output:**

```
WARN  HikariPool-1 - Connection leak detection triggered for connection
      Stack trace: 
        at com.example.BadService.method(BadService.java:42)
        at ...
```

---

## 8. Connection Pool Monitoring

### Key Metrics to Monitor

| Metric | Healthy Value | Alert When |
|--------|---------------|------------|
| **Active Connections** | Below max | Near max (80%+) |
| **Pending Requests** | 0-5 | Growing queue |
| **Connection Wait Time** | 1-10ms | More than 100ms consistently |
| **Connection Acquisition Failures** | 0 | Any failures |

### Monitoring with Actuator

```yaml
# Enable Hikari metrics
management:
  endpoints:
    web:
      exposure:
        include: health,metrics
  metrics:
    enable:
      hikari: true
```

**Metrics endpoint:**

```http
GET /actuator/metrics/hikaricp.connections.active
GET /actuator/metrics/hikaricp.connections.idle
GET /actuator/metrics/hikaricp.connections.pending
GET /actuator/metrics/hikaricp.connections.timeout
```

### Prometheus/Grafana Setup

```java
// Automatic with micrometer-registry-prometheus
// Metrics exposed at /actuator/prometheus

hikaricp_connections_active{pool="HikariPool-1"} 5
hikaricp_connections_idle{pool="HikariPool-1"} 3
hikaricp_connections_pending{pool="HikariPool-1"} 0
hikaricp_connections_max{pool="HikariPool-1"} 10
```

---

## 9. Best Practices

### Pagination Best Practices

```
âœ… DO:
â”œâ”€â”€ Use cursor pagination for infinite scroll / mobile apps
â”œâ”€â”€ Use OFFSET for admin panels with jump-to-page
â”œâ”€â”€ Always include ORDER BY with LIMIT
â”œâ”€â”€ Index the columns used in ORDER BY
â””â”€â”€ Set reasonable LIMIT (10-100, not 1000+)

âŒ DON'T:
â”œâ”€â”€ Use OFFSET > 10000 on production APIs
â”œâ”€â”€ Paginate without ORDER BY (random order!)
â””â”€â”€ Return 1000+ items per page
```

### Connection Pool Best Practices

```
âœ… DO:
â”œâ”€â”€ Size pool based on formula (cores Ã— 2)
â”œâ”€â”€ Set connection-timeout (don't wait forever)
â”œâ”€â”€ Enable leak detection in development
â”œâ”€â”€ Monitor active connections
â””â”€â”€ Use try-with-resources for raw JDBC

âŒ DON'T:
â”œâ”€â”€ Set pool size to 100+ without reason
â”œâ”€â”€ Do I/O calls inside transactions
â”œâ”€â”€ Hold connections longer than necessary
â””â”€â”€ Ignore connection timeout exceptions
```

---

## 10. Top Interview Questions

### Q1: What is the problem with OFFSET pagination?

**Answer:** OFFSET has O(N) complexity because the database must:
1. Scan and sort all rows
2. Skip the first N rows (wasted work)
3. Return the requested rows

For `OFFSET 1000000`, it scans 1 million rows just to skip them. This gets progressively slower as the offset increases.

### Q2: How does cursor-based pagination solve this?

**Answer:** Cursor pagination uses indexed column values (like `id > 1000`) instead of row positions. The database can:
1. Use the index to jump directly to the cursor position
2. Scan only the requested rows

This gives O(log N) performance that doesn't degrade with pagination depth.

### Q3: What is connection pooling and why is it needed?

**Answer:** Connection pooling maintains a set of pre-opened database connections that are reused across requests. It's needed because:
1. Opening a connection is expensive (50-200ms for TCP, SSL, auth)
2. Pooled connections are borrowed and returned (1ms overhead)
3. Limits total connections to the database (prevents overload)

### Q4: How do you size a connection pool?

**Answer:** Use the formula: `connections = (core_count Ã— 2) + spindle_count`

For a 4-core server with SSD: ~10 connections

Too few: requests wait in queue
Too many: context switching overhead and memory waste

### Q5: How do you detect connection leaks?

**Answer:**
1. Enable HikariCP leak detection: `leak-detection-threshold: 60000`
2. Monitor metrics: `hikaricp.connections.active` near max
3. Watch for `Connection timeout` errors
4. Check for code that doesn't close connections (missing try-with-resources)

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             PAGINATION & POOLING CHEAT SHEET                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚ PAGINATION:                                                      â”‚
â”‚ â”œâ”€â”€ OFFSET: Simple, O(N), OK for small data                    â”‚
â”‚ â””â”€â”€ CURSOR: Complex, O(log N), best for large data/APIs        â”‚
â”‚                                                                  â”‚
â”‚ CURSOR PAGINATION:                                               â”‚
â”‚ â””â”€â”€ SELECT * FROM t WHERE id > :cursor ORDER BY id LIMIT 10    â”‚
â”‚                                                                  â”‚
â”‚ CONNECTION POOL SIZING:                                          â”‚
â”‚ â””â”€â”€ Pool Size = (CPU Cores Ã— 2) + Spindles                      â”‚
â”‚     4 cores â†’ ~10 connections                                   â”‚
â”‚                                                                  â”‚
â”‚ HIKARICP CONFIG (application.yml):                               â”‚
â”‚ â””â”€â”€ maximum-pool-size: 10                                       â”‚
â”‚     connection-timeout: 30000                                   â”‚
â”‚     leak-detection-threshold: 60000                             â”‚
â”‚                                                                  â”‚
â”‚ CONNECTION LEAK CAUSES:                                          â”‚
â”‚ â”œâ”€â”€ Connection not closed (use try-with-resources!)            â”‚
â”‚ â”œâ”€â”€ Slow queries                                                â”‚
â”‚ â””â”€â”€ I/O inside transactions                                     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
